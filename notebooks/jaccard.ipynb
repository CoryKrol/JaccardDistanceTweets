{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jaccard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoryTee/JaccardDistanceTweets/blob/master/notebooks/jaccard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WI84NUscJqxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "from typing import Dict, Any\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "divider = '\\t\\t----------------------------------------------------------------'\n",
        "\n",
        "\"\"\"\n",
        "handle files using a callback method, prevents repetition\n",
        "\n",
        "source:\n",
        "https://stackoverflow.com/questions/3277503/how-to-read-a-file-line-by-line-into-a-list\n",
        "\"\"\"\n",
        "\n",
        "def _FileIO__file_handler(file_path, mode, callback = lambda f: None):\n",
        "  f = open(file_path, mode)\n",
        "  try:\n",
        "    return callback(f)\n",
        "  except Exception as e:\n",
        "    raise IOError(\"Failed to %s file\" % [\"write to\", \"read from\"][mode.lower() in \"r rb r+\".split(\" \")])\n",
        "  finally:\n",
        "    f.close()\n",
        "\n",
        "\n",
        "class FileIO:\n",
        "  # return the contents of a file\n",
        "  def read(file_path, mode = \"r\"):\n",
        "    return __file_handler(file_path, mode, lambda rf: rf.read())\n",
        "\n",
        "  # get the lines of a file\n",
        "  def lines(file_path, mode = \"r\", filter_fn = lambda line: len(line) > 0):\n",
        "    return [line for line in FileIO.read(file_path, mode).strip().split(\"\\n\") if filter_fn(line)]\n",
        "\n",
        "  # create or update a file (NOTE: can also be used to replace a file's original content)\n",
        "  def write(file_path, new_content, mode = \"w\"):\n",
        "    return __file_handler(file_path, mode, lambda wf: wf.write(new_content))\n",
        "\n",
        "  # delete a file (if it exists)\n",
        "  def delete(file_path):\n",
        "    return os.remove() if os.path.isfile(file_path) else None\n",
        "\n",
        "def jaccard_dist(set_a, set_b):\n",
        "  \"\"\"\n",
        "  Computes the Jaccard Distance of two sample sets (A and B) which measures \n",
        "  dissimilarity between them. It is defined as the difference of the sizes of \n",
        "  the union and the intersection of two sets divided by the size of the union \n",
        "  of the sets.\n",
        "  \n",
        "  JD(a, b) = 1 - (|a_intersect_b|/|a_union_b|)\n",
        "  \n",
        "  How to interpret the result:\n",
        "    -Small if the tweets are similar\n",
        "    -Large if the tweets are not similar\n",
        "    -0 if the tweets have the same words (not counting duplicates or ordering)\n",
        "    -1 if they are completely different (i.e. no overlapping words)\n",
        "    \n",
        "  http://en.wikipedia.org/wiki/Jaccard_index\n",
        "  \"\"\"\n",
        "  \n",
        "  a_union_b = len(set_a.union(set_b))\n",
        "  a_intersect_b = len(set_a.intersection(set_b))\n",
        "  \n",
        "  return  1.0 - (a_intersect_b / a_union_b)\n",
        " \n",
        "\"\"\"\n",
        "Misc helper functions\n",
        "\"\"\"\n",
        "def list_to_set(lst):\n",
        "  return set(lst)\n",
        "\n",
        "def print_iteration_results(clusters):\n",
        "  \"\"\"\n",
        "  A helper function for nicely formatting the results of each clusting iteration \n",
        "  and display the results\n",
        "  \"\"\"\n",
        "  cluster_count = 1\n",
        "  for keys, values in clusters.items():\n",
        "    #print(\"Iteration #%s:\\n\" % (str(iteration_num + 1),))\n",
        "    #iteration_num = iteration_num + 1\n",
        "    #\n",
        "    \n",
        "    print(\"Cluster #%s: \" % (str(cluster_count),), end='', flush=True)\n",
        "    \n",
        "    cluster_count = cluster_count + 1\n",
        "    \n",
        "    print(\"[\", end='', flush=True)\n",
        "\n",
        "    # Used to help format output\n",
        "    centroid_count = 0\n",
        "    for k in values:\n",
        "      centroid_count = centroid_count + 1\n",
        "\n",
        "      if centroid_count - 1 == 0 or (centroid_count -1) % 5 == 0:\n",
        "        print(\"%s\" % (str(k),), end='', flush=True)\n",
        "      elif centroid_count == len(values):\n",
        "        print(\"\", end='\\n\\n', flush=True)\n",
        "      elif centroid_count % 5 != 0 :\n",
        "        print(\", %s\" % (str(k),), end='', flush=True)\n",
        "      else:\n",
        "        print(\", %s,\" % (str(k),), end='\\n', flush=True)\n",
        "            \n",
        "    \n",
        "    print(divider, end='\\n\\n', flush=True)\n",
        "    \n",
        "    \n",
        "def is_equal_nested_lists(nlist_1, nlist_2):\n",
        "  \"\"\"\n",
        "  Determines if two nested lists are equivalent\n",
        "  \n",
        "  Used for determining convergence of this implementation of the K-Means \n",
        "  algorithm\n",
        "  \"\"\"\n",
        "  for key in nlist_1.keys():\n",
        "    if not is_equal_lists(nlist_1[key], nlist_2[key]):\n",
        "      return False\n",
        "  return True\n",
        "  \n",
        "def is_equal_lists(list_1, list_2):\n",
        "  \"\"\"\n",
        "  Determines if two lists contain the same elements\n",
        "  \"\"\"\n",
        "  set_1 = set(list_1)\n",
        "  set_2 = set(list_2)\n",
        "  \n",
        "  return set_1 == set_2\n",
        "\n",
        "\n",
        "def check_cluster_accuracy(cluster, nrows, k):\n",
        "  \"\"\"\n",
        "  A sanity check I should have coded long ago to help verify the correctness of\n",
        "  the K-Means implementation\n",
        "  \n",
        "  Basically checks if each iteration has the correct number of clusters(k) and \n",
        "  that each iteration is not erroneously missing or contain extra values\n",
        "  \"\"\"\n",
        "  # Return false is wrong number of clusters\n",
        "  num_clusters = len(cluster)\n",
        "  if num_clusters != k:\n",
        "    print(\"ERROR: INVALID NUMBER OF CLUSTERS: %s\" % (str(num_clusters),))\n",
        "    return False\n",
        "  \n",
        "  # Check to make sure no data was duplicated or lost\n",
        "  count = 0\n",
        "  for i in cluster:\n",
        "    count = count + len(i)\n",
        "    \n",
        "  if nrows != count:\n",
        "    print(\"ERROR: Invalid number of instances: %s\" % (str(count),))\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "def preprocess(data_url):\n",
        "  preprocessing_fun = ['P', 'r', 'e', 'p', 'r', 'o', 'c', 'e', 's', 's', 'i', 'n', 'g', ' ', 'd', 'a', 't', \n",
        "  'a', '.', '.',  '.',  '.',  '.',  '.',  '.',  '.', 'b', 'e',  '.',  '.',  '.', 'p', 'a', 't', 'i', 'e', 'n', 't', '.']\n",
        "  tweets = pd.read_json(data_url, lines=True, orient='records')\n",
        "\n",
        "  # Drop all columns except for the tweet text and the tweet id to save memory\n",
        "  tweets = tweets[['text', 'id']]\n",
        "\n",
        "  num_rows = tweets.shape[0]\n",
        "\n",
        "  # Split tweet text data using spaces and save to new 'list' column before set\n",
        "  # conversion then apply the set_from_list function to the new list 'column'\n",
        "  tweets['list'] = tweets['text'].str.split()\n",
        "\n",
        "  # Convert the lists of words for tweets into sets\n",
        "  tweets['set'] = tweets['list'].apply(list_to_set)\n",
        "\n",
        "  # Remove list column to free up memory\n",
        "  tweets = tweets.drop(['list'], axis=1)\n",
        "\n",
        "  # Create a new column of lists for Jaccard Distances to all other Tweets\n",
        "  distances_list = []\n",
        "  preprocess_fun_len = len(preprocessing_fun)\n",
        "  fun_iterations = 0\n",
        "  # Calculate Jaccard Distances between each tweet\n",
        "\n",
        "  for i in range(0, num_rows):\n",
        "    distances: Dict[str, float] = {}\n",
        "    \n",
        "    # Don't really need, but helps with debugging\n",
        "    tweet_a_id = str(tweets.loc[[i], ['id']]['id'][i])\n",
        "    set_a = tweets.loc[[i], ['set']]['set'][i]\n",
        "\n",
        "    if fun_iterations >= preprocess_fun_len:\n",
        "      print(preprocessing_fun[-1], end='', flush=True)\n",
        "    else:\n",
        "      print(preprocessing_fun[fun_iterations], end='', flush=True)\n",
        "    fun_iterations = fun_iterations + 1\n",
        "\n",
        "    for j in range(0, num_rows):\n",
        "      if i != j:\n",
        "        set_b = tweets.loc[[j], ['set']]['set'][j]\n",
        "\n",
        "        # Get ID for 2nd Tweet for identification during K-Means\n",
        "        tweet_b_id = str(tweets.loc[[j], ['id']]['id'][j])\n",
        "\n",
        "        # Calculate Jaccard Distance between tweets and save with the ID of the \n",
        "        # 2nd tweet\n",
        "        distances[tweet_b_id] = jaccard_dist(set_a, set_b)\n",
        "      else:\n",
        "        pass\n",
        "    \n",
        "    num_of_distances = len(distances) \n",
        "    \n",
        "    if num_of_distances != num_rows-1:\n",
        "      print('ERROR: Incorrect number of distances counted')\n",
        "      print('Number of Instances: %s' % (str(num_of_distances)))\n",
        "      print('Tweet ID: %s' % (tweet_a_id,))\n",
        "      \n",
        "    distances_list.append(distances)\n",
        "\n",
        "  list_size = len(distances_list)\n",
        "  if list_size != num_rows:\n",
        "    print('ERROR: Incorrect number of distance dictionaries generated')\n",
        "    print('Number of Dictionaries: %s' % (str(list_size)))\n",
        "    print('Required: %s' % (str(num_rows),))\n",
        "\n",
        "  print('')\n",
        "  tweets = tweets.assign(distances=pd.Series(distances_list).values)\n",
        "  return tweets\n",
        "\n",
        "def read_seeds(seed_location):\n",
        "  # Read in seeds from file\n",
        "  centroid_ids = []\n",
        "  file_ext_lines = FileIO.lines(seed_location)\n",
        "  for i, line in enumerate(file_ext_lines):\n",
        "    #Drop comma from end of line\n",
        "    if line[-1:] is \",\":\n",
        "      centroid_ids.append(line[:-1])\n",
        "    else:\n",
        "      centroid_ids.append(line)\n",
        "\n",
        "  return centroid_ids\n",
        "\n",
        "def output_results(clusters, overall_sse, filename):\n",
        "  \n",
        "  with open(filename, 'w') as f:\n",
        "    for key, cluster in clusters.items():\n",
        "      f.write(\"%s : \" % (str(key),))\n",
        "      for i in cluster:\n",
        "        f.write(\"%s, \" % (str(i),))\n",
        "      f.write(\"\\n\")\n",
        "      \n",
        "    f.write(\"%s\" % str(round(overall_sse, 3)))\n",
        "\n",
        "def k_means(seeds, tweets):\n",
        "  centroids = seeds\n",
        "  random = tweets.sample(25)['id']\n",
        "  centroids = []\n",
        "  for i in random:\n",
        "    centroids.append(str(i))\n",
        "\n",
        "  centroids = seeds\n",
        "  clusters = cluster_assignment(centroids, tweets)\n",
        "  \n",
        "\n",
        "  converged = False\n",
        "  num_iterations = 1\n",
        "  print(\"Iteration: %s\\n\" % (str(num_iterations),))\n",
        "  print_iteration_results(clusters)\n",
        "  while not converged:\n",
        "\n",
        "    num_iterations = num_iterations + 1\n",
        "    print(\"Iteration: %s\\n\" % (str(num_iterations),))\n",
        "    # Calculate new centroids for next clustering round\n",
        "    new_centroids = calculate_new_centroids(clusters, tweets)\n",
        "    if is_equal_lists(centroids, new_centroids):\n",
        "      print('No change in centroids')\n",
        "      \n",
        "    # Assign to clusters clusters \n",
        "    new_clusters = cluster_assignment(new_centroids, tweets)\n",
        "    \n",
        "    if is_equal_nested_lists(clusters, new_clusters):\n",
        "      print('\\tClusters are the same so convergence', end='\\n\\n', flush=True)\n",
        "      converged = True\n",
        "      clusters = new_clusters\n",
        "      centroids = new_centroids\n",
        "      print_iteration_results(new_clusters)\n",
        "      break\n",
        "      \n",
        "    \n",
        "    clusters = new_clusters\n",
        "    centroids = new_centroids\n",
        "    print_iteration_results(new_clusters)\n",
        "    \n",
        "  return {'centroids' : centroids, 'clusters' : clusters}\n",
        "\n",
        "\n",
        "def cluster_assignment(centroid_ids, tweets):\n",
        "  \"\"\"\n",
        "  A function that accepts a list of strings correspoding to the IDs of tweets\n",
        "  that are the centroids for the clusters and an already pre-processed pandas \n",
        "  dataframe of tweets\n",
        "  \"\"\"\n",
        "  # The list of nodes at each cluster\n",
        "  clusters = {}\n",
        "  \n",
        "  # Initialize nested lists to hold cluster member ID and add the centroid's ID\n",
        "  i = 0\n",
        "  for cur_id in centroid_ids:\n",
        "    clusters[i] = [str(cur_id)]\n",
        "    i = i+1\n",
        "  \n",
        "  for i in range(0, num_rows):\n",
        "    current_id = str(tweets.loc[[i], ['id']]['id'][i])\n",
        "    \n",
        "    # Skip as we already added the centoid ID to cluster\n",
        "    if current_id in centroid_ids:\n",
        "      pass\n",
        "    else:\n",
        "      # Get dictionary of distances from this node to all others and their IDs\n",
        "      distances = tweets[tweets['id'] == np.int64(current_id)]['distances'][i]\n",
        "\n",
        "      dist_to_centroids = {k: distances[str(k)] for k in centroid_ids}\n",
        "      \n",
        "      closest_centroid = str(min(dist_to_centroids, key=dist_to_centroids.get))\n",
        "            \n",
        "      index = centroid_ids.index(closest_centroid)\n",
        "      (clusters[index]).append(current_id)\n",
        "      \n",
        "  return clusters\n",
        "\n",
        "\n",
        "def calculate_new_centroids(clusters, tweets):\n",
        "  new_centroids = []\n",
        "  \n",
        "  for key, value in clusters.items():\n",
        "    new_centroid = str(find_new_cluster_center(value, tweets))\n",
        "    \n",
        "    new_centroids.append(new_centroid)\n",
        "\n",
        "  return new_centroids\n",
        "  \n",
        "  \n",
        "def find_new_cluster_center(cluster_ids, tweets):\n",
        "  distance_sums = {}\n",
        "  \n",
        "  for tweet_id in cluster_ids:\n",
        "    distance_sums[tweet_id] = calc_dist_to_other_nodes(tweet_id, \n",
        "                                                            cluster_ids, tweets)\n",
        "    \n",
        "  return min(distance_sums, key=distance_sums.get)\n",
        "  \n",
        "  \n",
        "def calc_dist_to_other_nodes(current_id, cluster_ids, tweets):\n",
        "  # Get distance data for current tweet (row in tweets df) to all others\n",
        "  distances = tweets.loc[tweets['id'] == np.int64(current_id)]['distances']\n",
        "  \n",
        "  # distances is a pandas.Serial object, with values returning a list, and in our\n",
        "  # case there is only one entry\n",
        "  distances = distances.values[0]\n",
        "  \n",
        "  dist_sum = 0.0\n",
        "  \n",
        "  for i in cluster_ids:\n",
        "    if str(i) != current_id:\n",
        "      dist_sum = dist_sum + distances[str(i)]\n",
        "\n",
        "  return dist_sum\n",
        "\n",
        "\n",
        "def compute_sse(clusters, centroid_ids, tweets):\n",
        "  sse = 0.0\n",
        "  \n",
        "  for key, cluster in clusters.items():\n",
        "    for i in cluster:\n",
        "      # Ignore the centroid's data when we come to is\n",
        "      if i in centroid_ids:\n",
        "        pass\n",
        "      else:\n",
        "        distances = tweets[tweets['id'] == np.int64(i)]['distances']\n",
        "        distances = distances.values[0]\n",
        "        \n",
        "        sse = sse + math.pow(float(distances[centroid_ids[key]]), 2)\n",
        "        \n",
        "  return sse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhTt6VOBJskq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "527ff8e7-c548-4930-dfda-53e71ade2b48"
      },
      "cell_type": "code",
      "source": [
        "NUM_CLUSTERS = 25\n",
        "seed_location = '/content/InitialSeeds.txt'\n",
        "data_url = 'file://localhost/content/Tweets.json'\n",
        "output_file = '/content/tweets-k-means-output.txt'\n",
        "\n",
        "tweets = preprocess(data_url)\n",
        "centroid_ids = read_seeds(seed_location)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing data........be...patient.....................................................................................................................................................................................................................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J9gF_3sVLYyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4715
        },
        "outputId": "d66ea6ad-5c15-4dd4-a822-7740663cbb28"
      },
      "cell_type": "code",
      "source": [
        "results = k_means(centroid_ids, tweets)\n",
        "centroids = results['centroids']\n",
        "clusters = results['clusters']\n",
        "overall_sse = compute_sse(clusters, centroids, tweets)\n",
        "print('Sum of Squared Errors: %s' % (str(round(overall_sse, 3)),))\n",
        "\n",
        "output_results(clusters, overall_sse, output_file)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1\n",
            "\n",
            "Cluster #1: [323906397735641088, 323906397609791488, 323906397618196483, 323906397853073410, 323906397962121216,\n",
            "323906398012461057, 323906398230544385, 323906398314438656, 323906398352195585, 323906398826164225,\n",
            "323906398993932289, 323906399149109248, 323906399295926273, 323906399300100096, 323906656318676993,\n",
            "323907087551836160, 323907771256938496, 323908455545049088, 323908795254312962\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #2: [323906483584655360, 323906485249789952, 323911610236293120, 323915000567697409, 323916051614138368,\n",
            "323920146454425600, 323921510282702848, 323923559799996417\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #3: [323906657333682176, 323906650987692034, 323906651209994241\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #4: [323907258301939713, 323906398176030720, 323906567294562306, 323910330315075584, 323910330457669633,\n",
            "323955716392112128, 323963901769297921, 324226045052071936\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #5: [323909308188344320\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #6: [323913403460636673, 323906398423490561, 323906482489921537, 323906484629032960, 323911097818173440,\n",
            "323913403951357953, 323913746231750656, 323915624835342337, 323916814490939393, 323917413789868034,\n",
            "323918009901150208, 323919716039155712, 323921167381577728, 323922279182520320, 323924155391164416,\n",
            "323924496144797697, 323924665074581504, 323925432548335616, 323927822072684544, 323928504523694080,\n",
            "323929272685318147, 323930212121317377, 323932515599515649, 323933624816787456, 323944113764438016,\n",
            "323946504752603136\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #7: [324067437886713856, 324038827578626048, 324210976629067776\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #8: [324117950774775809\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #9: [324138055772561408, 324002623571255296, 324070589214117888, 324125626284007424, 324132606608306176,\n",
            "324154782782742529, 324160230760005632, 324179340675915779, 324188481918230528, 324227779530985472,\n",
            "324460055724433408\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #10: [324219503401644033, 324358798179459073, 324366333829586945, 324375472681148416, 324376801382133761,\n",
            "324419757661097984\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #11: [324320247018573824, 324327405743382529, 324327410344542208, 324423829088784384, 324425542629732352,\n",
            "324427314060484608, 324427596253253633, 324427930631544832\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #12: [324346553835868161, 324348252763873283, 324368024561909760, 324351038741901865, 324326736198238763,\n",
            "324334932112843721, 324310958418232934, 324354128398432734, 324337983412847463, 324373063433847463,\n",
            "324382984012350293\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #13: [324372750330363904, 324380629779247106, 324418112688623616, 324458862537228289\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #14: [324408472441585664, 324408861563944960, 324409861041438720, 324409871061618689, 324432383115935744,\n",
            "324437436077854721, 324438127102013440, 324439166496690176, 324439832715747328, 324440178842296321,\n",
            "324441529030701057, 324441544377634816, 324445289912074240, 324445292130877440, 324446653635522560,\n",
            "324452116863258624\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #15: [324422817565257728, 324423146381901825, 324423157106749441, 324423160525103105, 324423494098120705,\n",
            "324423506957852672\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #16: [324448013999304704, 324448359932887040, 324448711860158464, 324451075501457408\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #17: [324785120085176320, 324785122073251840, 324785129241341952, 324785131569168384, 324787508997144576,\n",
            "324790912431583232\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #18: [325059351209443329, 325059374814994434, 325059598488829953, 325059948511899648, 325059996704452608,\n",
            "325060608246562816, 325061078994284544\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #19: [325060324992643072, 325060138891350016, 325060145082163200, 325060154087309312\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #20: [325162944931438592, 325163043233337344, 325165164561330176, 325166486215856129, 325170591164403712,\n",
            "325170934115864576, 325171288526163968, 325171606253080577, 325172960413503489, 325173634563964929,\n",
            "325175391654408192, 325176378595102720\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #21: [325253327048822784, 325253327640223744, 325253669408874496, 325253670746849280, 325253670780416000,\n",
            "325254353877352448\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #22: [325337623910559745, 325329802032721920, 325335253487063041, 325337627857387521, 325337640322871296,\n",
            "325338650076405761, 325342218942554112, 325350010961141760\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #23: [325409910642835456, 325409910588317696, 325409910714138625, 325409910827401217, 325409910869327872,\n",
            "325409910886117377, 325409927193567232, 325409992121389058, 325409996290527232, 325409996529602560,\n",
            "325409996726743041, 325409996764479488, 325409996965810176, 325410254697414658, 325410327036571649,\n",
            "325410327183364096, 325410327200145409\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #24: [325701934273134594, 325701932083716096, 325701941478973440, 325702031912349696, 325702115865538560,\n",
            "325702269288992768, 325702271591665664, 325702273684627456, 325702285621612545, 325702287978795009,\n",
            "325702294287048705, 325702294928764929, 325702363174285312, 325702375430057984, 325702377279729664,\n",
            "325702626169729024, 325702632603803648, 325702633174204416, 325702635405574145, 325702711729348608,\n",
            "325702890297643008, 325702936036524032, 325702950859198464, 325702955896553472, 325702956185948160,\n",
            "325702958786441216\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #25: [325946633986641920, 325917940564250624, 325927476566032385, 325946283368013824, 325946659739668480,\n",
            "325946918842818560, 325947086145212416, 325947301745029121, 325947340777222145\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Iteration: 2\n",
            "\n",
            "\tClusters are the same so convergence\n",
            "\n",
            "Cluster #1: [323906397735641088, 323906397609791488, 323906397618196483, 323906397853073410, 323906397962121216,\n",
            "323906398012461057, 323906398230544385, 323906398314438656, 323906398352195585, 323906398826164225,\n",
            "323906398993932289, 323906399149109248, 323906399295926273, 323906399300100096, 323906656318676993,\n",
            "323907087551836160, 323907771256938496, 323908455545049088, 323908795254312962\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #2: [323906485249789952, 323906483584655360, 323911610236293120, 323915000567697409, 323916051614138368,\n",
            "323920146454425600, 323921510282702848, 323923559799996417\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #3: [323906651209994241, 323906650987692034, 323906653651079168\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #4: [323907258301939713, 323906398176030720, 323906567294562306, 323910330315075584, 323910330457669633,\n",
            "323955716392112128, 323963901769297921, 324226045052071936\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #5: [323909308188344320\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #6: [323913403460636673, 323906398423490561, 323906482489921537, 323906484629032960, 323911097818173440,\n",
            "323913403951357953, 323913746231750656, 323915624835342337, 323916814490939393, 323917413789868034,\n",
            "323918009901150208, 323919716039155712, 323921167381577728, 323922279182520320, 323924155391164416,\n",
            "323924496144797697, 323924665074581504, 323925432548335616, 323927822072684544, 323928504523694080,\n",
            "323929272685318147, 323930212121317377, 323932515599515649, 323933624816787456, 323944113764438016,\n",
            "323946504752603136\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #7: [324067437886713856, 324038827578626048, 324210976629067776\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #8: [324117950774775809\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #9: [324070589214117888, 324002623571255296, 324125626284007424, 324132606608306176, 324138055772561408,\n",
            "324154782782742529, 324160230760005632, 324179340675915779, 324188481918230528, 324227779530985472,\n",
            "324460055724433408\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #10: [324375472681148416, 324219503401644033, 324358798179459073, 324366333829586945, 324376801382133761,\n",
            "324419757661097984\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #11: [324427314060484608, 324320247018573824, 324327405743382529, 324327410344542208, 324423829088784384,\n",
            "324425542629732352, 324427596253253633, 324427930631544832\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #12: [324348252763873283, 324346553835868161, 324368024561909760, 324351038741901865, 324326736198238763,\n",
            "324334932112843721, 324310958418232934, 324354128398432734, 324337983412847463, 324373063433847463,\n",
            "324382984012350293\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #13: [324372750330363904, 324380629779247106, 324418112688623616, 324458862537228289\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #14: [324408861563944960, 324408472441585664, 324409861041438720, 324409871061618689, 324432383115935744,\n",
            "324437436077854721, 324438127102013440, 324439166496690176, 324439832715747328, 324440178842296321,\n",
            "324441529030701057, 324441544377634816, 324445289912074240, 324445292130877440, 324446653635522560,\n",
            "324452116863258624\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #15: [324422817565257728, 324423146381901825, 324423157106749441, 324423160525103105, 324423494098120705,\n",
            "324423506957852672\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #16: [324448013999304704, 324448359932887040, 324448711860158464, 324451075501457408\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #17: [324785129241341952, 324785120085176320, 324785122073251840, 324785131569168384, 324787508997144576,\n",
            "324790912431583232\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #18: [325059351209443329, 325059374814994434, 325059598488829953, 325059948511899648, 325059996704452608,\n",
            "325060608246562816, 325061078994284544\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #19: [325060324992643072, 325060138891350016, 325060145082163200, 325060154087309312\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #20: [325171606253080577, 325162944931438592, 325163043233337344, 325165164561330176, 325166486215856129,\n",
            "325170591164403712, 325170934115864576, 325171288526163968, 325172960413503489, 325173634563964929,\n",
            "325175391654408192, 325176378595102720\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #21: [325253327048822784, 325253327640223744, 325253669408874496, 325253670746849280, 325253670780416000,\n",
            "325254353877352448\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #22: [325335253487063041, 325329802032721920, 325337623910559745, 325337627857387521, 325337640322871296,\n",
            "325338650076405761, 325342218942554112, 325350010961141760\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #23: [325409910642835456, 325409910588317696, 325409910714138625, 325409910827401217, 325409910869327872,\n",
            "325409910886117377, 325409927193567232, 325409992121389058, 325409996290527232, 325409996529602560,\n",
            "325409996726743041, 325409996764479488, 325409996965810176, 325410254697414658, 325410327036571649,\n",
            "325410327183364096, 325410327200145409\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #24: [325702890297643008, 325701932083716096, 325701934273134594, 325701941478973440, 325702031912349696,\n",
            "325702115865538560, 325702269288992768, 325702271591665664, 325702273684627456, 325702285621612545,\n",
            "325702287978795009, 325702294287048705, 325702294928764929, 325702363174285312, 325702375430057984,\n",
            "325702377279729664, 325702626169729024, 325702632603803648, 325702633174204416, 325702635405574145,\n",
            "325702711729348608, 325702936036524032, 325702950859198464, 325702955896553472, 325702956185948160,\n",
            "325702958786441216\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Cluster #25: [325946633986641920, 325917940564250624, 325927476566032385, 325946283368013824, 325946659739668480,\n",
            "325946918842818560, 325947086145212416, 325947301745029121, 325947340777222145\n",
            "\n",
            "\t\t----------------------------------------------------------------\n",
            "\n",
            "Sum of Squared Errors: 22.542\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}